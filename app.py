import io
import os
import time
from typing import Dict, Any

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st

# Si vas a disparar GitHub Actions desde la app, necesit√°s requests
try:
    import requests  # a√±adido a requirements.txt
except Exception:
    requests = None

from utils import (
    load_model, load_metadata, load_schema,
    validate_dataframe, pretty_metric_table
)

# ------------------------- Config b√°sica -------------------------
st.set_page_config(
    page_title="Income Predictor ‚Äì Demo lista para vender",
    page_icon="üìà",
    layout="wide"
)

st.markdown(
    "# üìà Income Predictor\n"
    "**Prototipo escalable, listo para demos y ventas.**\n\n"
    "Entrena con datos p√∫blicos reales (OpenML *Adult*), compara modelos, "
    "elige el mejor y permite **scorear en tiempo real** por formulario o por archivo.\n"
)

with st.expander("‚ÑπÔ∏è C√≥mo funciona"):
    st.markdown(
        "- **Datos:** OpenML *Adult* (ingresos > USD 50k).\n"
        "- **Modelos:** Regresi√≥n Log√≠stica, Random Forest, XGBoost (selecci√≥n autom√°tica por ROC AUC).\n"
        "- **M√©tricas:** ROC AUC (CV), precisi√≥n, F1 en hold-out.\n"
        "- **Arquitectura recomendada:** GitHub Actions entrena y commitea el modelo; "
        "Streamlit Cloud sirve la UI y **lee** el modelo del repo.\n"
    )

# ------------------------- KPIs de cabecera -------------------------
meta_header = load_metadata()
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("Estado del modelo", "Cargado" if load_model() else "No encontrado")
with col2:
    st.metric("Mejor modelo", meta_header.get("best_model", "‚Äî"))
with col3:
    st.metric("Rows dataset", meta_header.get("rows", "‚Äî"))

st.divider()

# ------------------------- Tabs -------------------------
tab_overview, tab_train, tab_realtime, tab_batch, tab_monitor = st.tabs(
    ["üìä Overview", "üõ†Ô∏è Entrenar", "üßÆ Scoring en tiempo real", "üìÇ Scoring por archivo", "üì° Monitor"]
)

# ========================= 1) OVERVIEW =========================
with tab_overview:
    meta = load_metadata()
    if meta:
        st.subheader("Resumen del experimento")
        cv_df = pretty_metric_table(meta.get("cv", []))
        st.dataframe(cv_df, use_container_width=True)
        holdout = meta.get("holdout", {})
        st.write("**Hold-out:**", holdout)
        if not cv_df.empty:
            fig = px.bar(
                cv_df, x="model", y="roc_auc",
                error_y="roc_auc_std",
                title="ROC AUC (CV) por modelo"
            )
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No hay metadatos a√∫n. Ve a **Entrenar** para generar el primer modelo.")

# ========================= 2) TRAIN =========================
with tab_train:
    st.subheader("Entrenar / Re-entrenar")

    subtab_actions, subtab_local = st.tabs(["üöÄ GitHub Actions (recomendado)", "üß™ Local en el runtime (opcional)"])

    # ---------- A) Disparar GitHub Actions ----------
    with subtab_actions:
        st.caption("Dispara el workflow de GitHub; cuando termine y haga push, la app usar√° el nuevo modelo.")
        owner = st.secrets.get("GH_OWNER")
        repo = st.secrets.get("GH_REPO")
        ref = st.secrets.get("GH_REF", "main")
        workflow_path = st.secrets.get("GH_WORKFLOW", ".github/workflows/train.yml")
        token = st.secrets.get("GH_TOKEN")

        # URL √∫til para ver el workflow (si configuraste owner/repo)
        if owner and repo:
            actions_url = f"https://github.com/{owner}/{repo}/actions"
            st.link_button("üß≠ Ver workflows en GitHub Actions", actions_url, type="secondary")

        def trigger_workflow(owner: str, repo: str, workflow_path: str, ref: str, token: str):
            """
            Dispara workflow_dispatch. GitHub acepta:
            /actions/workflows/{workflow_id|file_name}/dispatches
            """
            # Usamos el nombre del archivo del workflow
            workflow_file = workflow_path.split("/")[-1]
            url = f"https://api.github.com/repos/{owner}/{repo}/actions/workflows/{workflow_file}/dispatches"
            headers = {
                "Authorization": f"Bearer {token}",
                "Accept": "application/vnd.github+json"
            }
            data = {"ref": ref}
            return requests.post(url, headers=headers, json=data, timeout=30)

        disabled = not all([owner, repo, token]) or (requests is None)
        if not requests:
            st.warning("Falta el paquete 'requests'. Asegurate de tenerlo en requirements.txt (requests>=2.31).")

        with st.form("form_actions"):
            run_now = st.form_submit_button("üîÅ Disparar re-entreno en GitHub")
        if run_now:
            if disabled:
                st.error("Faltan secretos GH_TOKEN/GH_OWNER/GH_REPO o el paquete 'requests'. Configuralos en Settings ‚Üí Secrets de Streamlit.")
            else:
                with st.spinner("Lanzando workflow en GitHub Actions‚Ä¶"):
                    r = trigger_workflow(owner, repo, workflow_path, ref, token)
                if r.status_code in (201, 204):
                    st.success("Workflow disparado correctamente.")
                    st.info("Cuando el workflow termine y haga push, esta app leer√° el nuevo modelo del repo.")
                else:
                    st.error(f"Error al disparar el workflow ({r.status_code}): {r.text}")

    # ---------- B) Entrenamiento local (opcional; puede fallar en Streamlit Cloud) ----------
    with subtab_local:
        st.caption("Ejecuta `python train.py` en el entorno actual. √ötil en local; en Streamlit Cloud puede fallar por l√≠mites del entorno.")
        if st.button("‚ñ∂Ô∏è Entrenar aqu√≠ (local)"):
            with st.spinner("Entrenando‚Ä¶"):
                exit_code = os.system("python train.py")
                time.sleep(1.0)
            if exit_code == 0:
                # Limpiar cach√© y forzar recarga
                try:
                    st.cache_data.clear()
                except Exception:
                    pass
                try:
                    st.cache_resource.clear()
                except Exception:
                    pass
                st.success("Entrenamiento finalizado. Refrescando m√©tricas‚Ä¶")
                st.rerun()
            else:
                st.error("Fall√≥ el entrenamiento. Revis√° logs (consola/Actions).")

# ========================= 3) REAL-TIME SCORING =========================
with tab_realtime:
    st.subheader("Scoring individual")
    schema = load_schema()
    model = load_model()

    if not model or not schema:
        st.warning("Primero entren√° un modelo en la pesta√±a **Entrenar**.")
    else:
        with st.form("form_realtime"):
            inputs: Dict[str, Any] = {}
            for col in schema["columns"]:
                name = col["name"]
                if col["type"] == "numeric":
                    val = st.number_input(name, value=0.0, step=1.0, format="%.4f")
                else:
                    options = col.get("values") or []
                    if options:
                        val = st.selectbox(name, options=options, index=0 if options else None)
                    else:
                        val = st.text_input(name, "")
                inputs[name] = val

            submitted = st.form_submit_button("Scorear")

        if submitted:
            df = pd.DataFrame([inputs])
            df = validate_dataframe(df, schema)
            try:
                proba = float(model.predict_proba(df)[0, 1])
                st.success(f"Probabilidad de ingreso > 50k: **{proba:.3f}**")
                st.progress(proba)
            except Exception as e:
                st.error(f"No se pudo scorear el caso: {e}")

# ========================= 4) BATCH SCORING =========================
with tab_batch:
    st.subheader("Scoring por archivo (CSV)")
    st.caption("El CSV debe contener las columnas del esquema de entrada. Recibir√°s un archivo con una columna nueva: `score`.")
    schema = load_schema()
    model = load_model()

    if not model or not schema:
        st.warning("Primero entren√° un modelo en la pesta√±a **Entrenar**.")
    else:
        uploaded = st.file_uploader("Sub√≠ un CSV", type=["csv"])
        if uploaded:
            try:
                df = pd.read_csv(uploaded)
                df_val = validate_dataframe(df, schema)
                scores = model.predict_proba(df_val)[:, 1]
                out = df.copy()
                out["score"] = scores

                buf = io.BytesIO()
                out.to_csv(buf, index=False)
                st.download_button(
                    "‚¨áÔ∏è Descargar con scores",
                    data=buf.getvalue(),
                    file_name="scored.csv",
                    mime="text/csv"
                )
                st.success(f"Listo: {len(out)} filas scoreadas.")
            except Exception as e:
                st.error(f"No se pudo procesar el archivo: {e}")

# ========================= 5) MONITOR =========================
with tab_monitor:
    st.subheader("Informaci√≥n del modelo")
    meta = load_metadata()
    st.json(meta if meta else {"status": "No metadata yet"})
    st.caption("Tip: en producci√≥n pod√©s registrar estos metadatos en un dashboard propio o DataDog/Prometheus.")
